{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf1342de",
   "metadata": {},
   "source": [
    "# NB01: Data Collection - London Air Pollution\n",
    "## This notebook collects historical air pollution data from OpenWeather API\n",
    "\n",
    "## SECTION 1: IMPORT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc96bafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests  # For making API calls\n",
    "import os        # For file/folder operations\n",
    "import json      # For saving data in JSON format\n",
    "from dotenv import load_dotenv  # For loading API key securely\n",
    "from datetime import datetime, timedelta  # For handling dates\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96df1f7",
   "metadata": {},
   "source": [
    "# Why are we using these specific libraries?\n",
    "## Requests- \n",
    "Makes HTTP requests to communicate with web APIs. It is essential because The OpenWeather API is a web service that requires HTTP GET requests to retrieve data. While Python has a built-in 'urllib' library,'requests' is industry-standard because it simplifies API calls significantly.\n",
    "As demonstrated in W02 Lecture on API interactions, requests.get() handles:- URL construction with parameters,Authentication headers,Response parsing,Error handling (status codes)\n",
    "# How I tested my understanding: \n",
    "I ran requests.get() with a simple test endpoint (OpenWeather current weather) before attempting historical data collection to verify I understood the parameter structure.\n",
    "## python-dotenv- \n",
    "It loads environment variables from a .env file into Python. Hardcoding API keys directly in notebooks is a major security risk. If I share my notebook on GitHub or with classmates, my API key would be exposed, allowing others to use my OpenWeather account, hence it is critical for security. In W03 Lab we discussed reproducibility and why notebooks with hardcoded passwords/keys aren't shareable. This approach solves that problem.\n",
    "## json-\n",
    "Encodes and decodes JSON (JavaScript Object Notation) data format. The OpenWeather API returns data in JSON format, and we need to save the raw API response before transformation. JSON is human-readable (I can open the file in a text editor to inspect it), preserves nested data structures (lists, dictionaries), Language-agnostic, can be read by R, JavaScript, etc., Maintains data types (numbers stay numbers, not strings)\n",
    "# Why save raw JSON before transformation?: \n",
    "Following the principle discussed in W04 Lecture on data pipelines - we separate collection from transformation. This means if I make a mistake in NB02, I don't need to re-call the API(which is rate-limited). The raw data acts as a \"checkpoint\" in my workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfd5f92",
   "metadata": {},
   "source": [
    "## SECTION 2: LOAD API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc1492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API Key loaded! (First 8 characters: bff53b98...)\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Get API key from environment variable\n",
    "API_KEY = os.getenv('OPENWEATHER_API_KEY')\n",
    "# Check if API key was loaded successfully\n",
    "if API_KEY:\n",
    "    print(f\"API Key loaded! (First 8 characters: {API_KEY[:8]}...)\")\n",
    "else:\n",
    "    print(\"ERROR: API Key not found! Check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d1d4c",
   "metadata": {},
   "source": [
    "### Why do we use a .env file instead of putting the API key directly in the code?\n",
    "\n",
    "Security and shareability are the main reasons:\n",
    "\n",
    "SECURITY RISK: Hardcoding my API key (like API_KEY = \"bff53b982b...\") means anyone who sees my notebook can use my key. This could exhaust my rate limit (OpenWeather free tier = 1,000 calls/day) or cost me money on paid plans. Even worse, if I push to GitHub, the key stays in the commit history forever, even if I delete it later.\n",
    "\n",
    "PROFESSIONAL PRACTICE: The \"Twelve-Factor App\" methodology (industry standard) requires configuration like API keys to be stored in environment variables, not code.\n",
    "This separates credentials from logic, following the \"separation of concerns\" principle from W01.\n",
    "\n",
    "REPRODUCIBILITY: Using .env files means:I can share my notebook publicly (only shows os.getenv('OPENWEATHER_API_KEY')), Others can run my code by creating their own .env file with their own key. I add .env to .gitignore so it never gets committed. This approach was emphasised in W03 Lab when discussing reproducible research and secure coding practices. I tested this by printing the first 8 characters of my loaded key to verify load_dotenv() worked correctly before making API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7e025c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç Location: London (51.5074, -0.1278)\n",
      "üìÖ Start Date: 2022-01-01\n",
      "üìÖ End Date: 2024-12-31\n",
      "‚è±Ô∏è  Start Timestamp: 1640995200\n",
      "‚è±Ô∏è  End Timestamp: 1735689599\n"
     ]
    }
   ],
   "source": [
    "# %% SECTION 3: DEFINE PARAMETERS\n",
    "# London coordinates (central London)\n",
    "LATITUDE = 51.5074\n",
    "LONGITUDE = -0.1278\n",
    "\n",
    "# Time period for data collection\n",
    "# Let's get 3 years of data (2022-2024)\n",
    "END_DATE = datetime(2024, 12, 31, 23, 59, 59)\n",
    "START_DATE = datetime(2022, 1, 1, 0, 0, 0)\n",
    "\n",
    "# Convert to Unix timestamps (required by API)\n",
    "END_TIMESTAMP = int(END_DATE.timestamp())\n",
    "START_TIMESTAMP = int(START_DATE.timestamp())\n",
    "\n",
    "print(f\"üìç Location: London ({LATITUDE}, {LONGITUDE})\")\n",
    "print(f\"üìÖ Start Date: {START_DATE.strftime('%Y-%m-%d')}\")\n",
    "print(f\"üìÖ End Date: {END_DATE.strftime('%Y-%m-%d')}\")\n",
    "print(f\"‚è±Ô∏è  Start Timestamp: {START_TIMESTAMP}\")\n",
    "print(f\"‚è±Ô∏è  End Timestamp: {END_TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71093e27",
   "metadata": {},
   "source": [
    "### Why did you choose this time period? (2022-2024)\n",
    "I chose 2022-2024 (3 years) after careful consideration of several factors:\n",
    "\n",
    "STATISTICAL SIGNIFICANCE: Air quality data contains significant seasonal variation (higher pollution in winter due to heating, lower in summer). To identify genuine long-term trends rather than seasonal fluctuations, I need multiple complete years.\n",
    "\n",
    "RELEVANCE TO RESEARCH QUESTION: My question asks if London's air is getting \"better or worse\" - this requires recent data that reflects current conditions. \n",
    "Data from 2022-2024 is most relevant because:\n",
    "\n",
    "Post-COVID: 2020-2021 had abnormal pollution levels due to lockdowns (traffic reduced by ~70% in March-May 2020 according to UK DfT statistics). 2022 onwards represents \"normal\" urban activity patterns. Captures recent policy impacts (e.g., Ultra Low Emission Zone expansion in August 2023)\n",
    "\n",
    "API CONSTRAINTS: OpenWeather's free tier allows 1,000 API calls per day.\n",
    "Each call returns data for one location/time point. For 3 years of hourly data: 3 years √ó 365 days √ó 24 hours = 26,280 records, which fits within reasonable API limits when requested in appropriate chunks.\n",
    "\n",
    "DATA QUALITY: Recent years have better data completeness and accuracy.Modern monitoring equipment (post-2020) provides more reliable PM2.5 and NO‚ÇÇ measurements compared to older sensors.\n",
    "\n",
    "#### Alternatives I considered:\n",
    "5 years (2020-2024): Rejected because it includes COVID lockdown anomalies which would skew trend analysis and not reflect typical urban conditions.\n",
    "\n",
    "1 year (2024 only): Too short to distinguish trends from seasonal variation.\n",
    "\n",
    "10 years (2015-2024): Ideal for long-term trends BUT would exceed API rate limits significantly and include different measurement methodologies\n",
    "\n",
    "#### My decision balances:\n",
    "‚úì Statistical robustness (multiple seasonal cycles)\n",
    "‚úì Current relevance (post-COVID \"normal\")\n",
    "‚úì Practical constraints (API limits)\n",
    "‚úì Data quality (modern sensors)\n",
    "\n",
    "#### Testing approach: \n",
    "I initially tested with 1 week of data (Jan 1-7, 2024) to verify the API worked correctly before committing to the full 3-year download.\n",
    "\n",
    "#### Why did you choose these specific coordinates for London?\n",
    "I chose coordinates 51.5074¬∞N, -0.1278¬∞W (central London) after researching several location options:\n",
    "#### RESEARCH PROCESS:\n",
    "I investigated three potential coordinate sets to represent \"London\":\n",
    "Option 1: City of London (51.5074¬∞N, -0.1278¬∞W) - Financial district, very central.\n",
    "Option 2: Greater London centroid (51.5072¬∞N, -0.1276¬∞W) - Geographic center.\n",
    "Option 3: Heathrow area (51.4700¬∞N, -0.4543¬∞W) - Western suburbs near airport.\n",
    "Option 4: Canary Wharf (51.5055¬∞N, -0.0196¬∞W) - East London business district.\n",
    "#### DECISION: I selected City of London (51.5074¬∞N, -0.1278¬∞W) for these reasons:\n",
    "REPRESENTATIVE URBAN POLLUTION: This location experiences typical urban air quality issues - traffic emissions, building density, human activity - without the airport-specific pollution at Heathrow or industrial zones elsewhere. According to UK DEFRA's London Air Quality Network (https://www.londonair.org.uk/), this area has well-established monitoring stations that show representative central London conditions.\n",
    "POPULATION EXPOSURE: Central London has the highest daytime population density(approximately 500,000 workers + residents in square mile). When we ask if London's air is \"getting better or worse,\" we should focus on where most people are exposed to pollution. This makes the health relevance clearer.\n",
    "\n",
    "POLICY RELEVANCE: Central London is where air quality policies have been most aggressive:\n",
    "Congestion Charge Zone (since 2003)\n",
    "Ultra Low Emission Zone (ULEZ) expanded August 2023\n",
    "Measuring this location captures policy impact\n",
    "\n",
    "DATA CONSISTENCY: The City of London coordinates are commonly used in academic studies and government reports, making my findings comparable to existing research.\n",
    "\n",
    "AVOIDING CONFOUNDS: \n",
    "Heathrow: Would be dominated by aircraft emissions (not representative of urban London)\n",
    "Suburbs: Lower pollution, less representative of the \"London\" people think of\n",
    "Parks (Hyde Park, etc.): Would underestimate typical exposure\n",
    "\n",
    "#### How I found these coordinates:\n",
    "Used Google Maps to identify \"City of London\" and right-clicked for coordinates\n",
    "#Cross-referenced with UK DEFRA monitoring station locations to ensure this area has historical air quality data for validation\n",
    "Verified coordinates using https://www.latlong.net/\n",
    "\n",
    "#### Testing: \n",
    "I made a test API call with these coordinates before running the full data collection to verify OpenWeather has coverage for this location (some APIs have gaps in geographic coverage).\n",
    "\n",
    "### What is a Unix timestamp and why does the API need it?\n",
    "\n",
    "A Unix timestamp (also called \"Epoch time\" or \"POSIX time\") is a way of representing date and time as a single number: the number of seconds that have elapsed since January 1, 1970, 00:00:00 UTC (Coordinated Universal Time).\n",
    "For example:\n",
    "Unix timestamp 0 = January 1, 1970, 00:00:00 UTC\n",
    "This is a standardized system used across programming languages and databases.\n",
    "\n",
    "#### WHY DOES THE API NEED IT?\n",
    "UNAMBIGUOUS TIME REPRESENTATION: Human-readable dates like \"01/02/2024\" are ambiguous - is that February 1st (US format) or January 2nd (UK format)?\n",
    "Unix timestamps eliminate this confusion. 1706745600 means exactly one moment in time, regardless of where you are in the world.\n",
    "\n",
    "TIMEZONE INDEPENDENCE: OpenWeather's servers could be anywhere, and users could be requesting data from any timezone. Unix timestamps are ALWAYS in UTC, so there's no confusion about timezone conversions.\n",
    "\n",
    "COMPUTATIONAL EFFICIENCY: Computers process numbers much faster than strings. Comparing, sorting, and calculating with timestamps like 1640995200 is far more efficient than parsing \"2022-01-01T00:00:00+00:00\". For an API handling millions of requests, this efficiency matters.\n",
    "\n",
    "STANDARDIZATION: Unix timestamps are a universal standard across systems(Linux, macOS, Windows, databases, APIs). This means the OpenWeather API can be used by any programming language (Python, JavaScript, R, Java, etc.) without needing different date format parsers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "388e5965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó API Endpoint: http://api.openweathermap.org/data/2.5/air_pollution/history\n",
      "üì¶ Parameters: lat=51.5074, lon=-0.1278\n",
      "   Time range: 1640995200 to 1735689599\n"
     ]
    }
   ],
   "source": [
    "# %% SECTION 4: CONSTRUCT API REQUEST\n",
    "# The API endpoint for HISTORICAL air pollution data\n",
    "BASE_URL = \"http://api.openweathermap.org/data/2.5/air_pollution/history\"\n",
    "\n",
    "# Parameters for the API request\n",
    "params = {\n",
    "    'lat': LATITUDE,\n",
    "    'lon': LONGITUDE,\n",
    "    'start': START_TIMESTAMP,\n",
    "    'end': END_TIMESTAMP,\n",
    "    'appid': API_KEY\n",
    "}\n",
    "\n",
    "print(f\"üîó API Endpoint: {BASE_URL}\")\n",
    "print(f\"üì¶ Parameters: lat={LATITUDE}, lon={LONGITUDE}\")\n",
    "print(f\"   Time range: {START_TIMESTAMP} to {END_TIMESTAMP}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e14bbf0",
   "metadata": {},
   "source": [
    "### How did you figure out which API endpoints to use?\n",
    "I started with the OpenWeather API documentation (openweathermap.org/api) and navigated to the Air Pollution API section. The documentation showed three endpoints: current, forecast, and history. Since my question asks \"Is London's air getting better or worse?\", I need HISTORICAL data to analyze trends over time.\n",
    "\n",
    "### What other API endpoints were available and why didn't you use them?\n",
    "OpenWeather Air Pollution API has three endpoints:\n",
    "\n",
    "CURRENT (/air_pollution):\n",
    "Provides: Real-time air quality for right now, Why rejected: Only gives one snapshot, can't analyze trends over time, Use case: Real-time monitoring dashboards\n",
    "\n",
    "FORECAST (/air_pollution/forecast):\n",
    "Provides: Predicted air quality for next 5 days, Why rejected: Shows future predictions, not past measurements. Can't answer \"Is air getting better?\" with predictions, need actual historical data, Use case: Planning outdoor activities\n",
    "\n",
    "HISTORY (/air_pollution/history) ‚úì SELECTED:\n",
    "Provides: Measured air quality data from the past, Why chosen: Only option that provides historical data for trend analysis, Allows calculating year-over-year changes and seasonal patterns, Directly answers my research question\n",
    "\n",
    "### Decision matrix: \n",
    "History was the ONLY endpoint providing multi-year measure data needed for \"better or worse\" trend analysis. The others provide either single snapshots or predictions, neither suitable for historical trend detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769c350f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Making API request...\n",
      "‚è≥ This might take 10-30 seconds for 3 years of data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ API request successful!\n",
      "üìä Received 25968 hourly air pollution records\n"
     ]
    }
   ],
   "source": [
    "# %% SECTION 5: MAKE API REQUEST\n",
    "\n",
    "print(\" Making API request...\")\n",
    "print(\"This might take 10-30 seconds for 3 years of data...\")\n",
    "\n",
    "try:\n",
    "    # Make the GET request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    # Check if request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ API request successful!\")\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check how much data we got\n",
    "        num_records = len(data.get('list', []))\n",
    "        print(f\"üìä Received {num_records} hourly air pollution records\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå API request failed with status code: {response.status_code}\")\n",
    "        print(f\"Error message: {response.text}\")\n",
    "        data = None\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå An error occurred: {e}\")\n",
    "    data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afc2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Let's look at the structure of our data:\n",
      "Top-level keys: ['coord', 'list']\n",
      "\n",
      "üìã Structure of first record:\n",
      "{\n",
      "  \"main\": {\n",
      "    \"aqi\": 1\n",
      "  },\n",
      "  \"components\": {\n",
      "    \"co\": 230.31,\n",
      "    \"no\": 0.01,\n",
      "    \"no2\": 16.96,\n",
      "    \"o3\": 40.41,\n",
      "    \"so2\": 7.57,\n",
      "    \"pm2_5\": 9.6,\n",
      "    \"pm10\": 15.84,\n",
      "    \"nh3\": 0.09\n",
      "  },\n",
      "  \"dt\": 1640995200\n",
      "}\n",
      "\n",
      "üå´Ô∏è  Available pollutants: ['co', 'no', 'no2', 'o3', 'so2', 'pm2_5', 'pm10', 'nh3']\n"
     ]
    }
   ],
   "source": [
    "# %% SECTION 6: INSPECT THE DATA\n",
    "\n",
    "if data:\n",
    "    print(\"\\n Let's look at the structure of our data:\")\n",
    "    print(f\"Top-level keys: {list(data.keys())}\")\n",
    "    \n",
    "    # Look at the first record\n",
    "    if 'list' in data and len(data['list']) > 0:\n",
    "        first_record = data['list'][0]\n",
    "        print(\"\\n Structure of first record:\")\n",
    "        print(json.dumps(first_record, indent=2))\n",
    "        \n",
    "        # What pollutants do we have?\n",
    "        if 'components' in first_record:\n",
    "            pollutants = list(first_record['components'].keys())\n",
    "            print(f\"\\n Available pollutants: {pollutants}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89242c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data saved successfully to: data/london_air_pollution_2022-2024.json\n",
      "üìÅ File size: 6.90 MB\n"
     ]
    }
   ],
   "source": [
    "# %% SECTION 7: SAVE DATA TO JSON FILE\n",
    "\n",
    "# Create data folder if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Filename with timestamp\n",
    "filename = f\"data/london_air_pollution_{START_DATE.year}-{END_DATE.year}.json\"\n",
    "\n",
    "if data:\n",
    "    try:\n",
    "        # Save to JSON file\n",
    "        with open(filename, 'w') as f:\n",
    "            json.dump(data, f, indent=2)\n",
    "        \n",
    "        print(f\"‚úÖ Data saved successfully to: {filename}\")\n",
    "        \n",
    "        # Check file size\n",
    "        file_size_mb = os.path.getsize(filename) / (1024 * 1024)\n",
    "        print(f\"üìÅ File size: {file_size_mb:.2f} MB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving file: {e}\")\n",
    "else:\n",
    "    print(\"‚ùå No data to save - API request failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f058cdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "üìä DATA COLLECTION SUMMARY\n",
      "==================================================\n",
      "‚úÖ Successfully collected 25,968 records\n",
      "üìÖ Date range: 2022-01-01 to 2024-12-31\n",
      "üìç Location: London (51.5074, -0.1278)\n",
      "üíæ Saved to: data/london_air_pollution_2022-2024.json\n",
      "\n",
      "üéØ Next step: Move to NB02-Data-Transformation.ipynb\n"
     ]
    }
   ],
   "source": [
    "# %% SECTION 8: SUMMARY\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìä DATA COLLECTION SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if data and 'list' in data:\n",
    "    num_records = len(data['list'])\n",
    "    \n",
    "    # Calculate date range from actual data\n",
    "    first_dt = datetime.fromtimestamp(data['list'][0]['dt'])\n",
    "    last_dt = datetime.fromtimestamp(data['list'][-1]['dt'])\n",
    "    \n",
    "    print(f\"‚úÖ Successfully collected {num_records:,} records\")\n",
    "    print(f\"üìÖ Date range: {first_dt.strftime('%Y-%m-%d')} to {last_dt.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"üìç Location: London ({LATITUDE}, {LONGITUDE})\")\n",
    "    print(f\"üíæ Saved to: {filename}\")\n",
    "    print(f\"\\nüéØ Next step: Move to NB02-Data-Transformation.ipynb\")\n",
    "else:\n",
    "    print(\"‚ùå Data collection failed - review error messages above\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "973ea0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% PROFESSIONAL ERROR HANDLING\n",
    "import time\n",
    "\n",
    "def fetch_with_retry(url, params, max_retries=3):\n",
    "    \"\"\"\n",
    "    Fetch data from API with automatic retry logic.\n",
    "    Implements exponential backoff for rate limit handling.\n",
    "    \"\"\"\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                return response\n",
    "            elif response.status_code == 429:  # Rate limit\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"‚è≥ Rate limited. Waiting {wait_time}s before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "            elif response.status_code == 401:\n",
    "                print(f\"‚ùå Authentication failed. Check API key.\")\n",
    "                return None\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Unexpected status: {response.status_code}\")\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"‚è±Ô∏è Request timeout on attempt {attempt + 1}/{max_retries}\")\n",
    "        except requests.exceptions.ConnectionError:\n",
    "            print(f\"üîå Connection error on attempt {attempt + 1}/{max_retries}\")\n",
    "            \n",
    "    print(f\"‚ùå Failed after {max_retries} attempts\")\n",
    "    return None\n",
    "\n",
    "# Use it in your API call\n",
    "response = fetch_with_retry(BASE_URL, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ebf1e",
   "metadata": {},
   "source": [
    "### SUMMARY REFLECTION \n",
    "#### Overall reflection: What was challenging about this notebook?\n",
    "#### Answer: \n",
    "The most challenging aspect was navigating the OpenWeather API limitations and understanding why historical data access took time to activate. Initially, I assumed that once my API key showed as \"Active\" on the dashboard, all endpoints would be immediately accessible. However, I discovered through trial and error (and the 401 error) that historical data access requires additional activation time beyond the basic key activation.\n",
    "#### Were there any errors you had to debug? What was more complex than expected?\n",
    "Understanding Unix timestamps was also initially confusing - converting between human-readable dates and seconds-since-1970 required careful testing to ensure I didn't accidentally request the wrong time period. I used online converters to verify my datetime calculations before running the full API request.\n",
    "#### What did you learn about API authentication and data collection?\n",
    "I learned that APIs often have multiple endpoints for different purposes (current vs forecast vs historical). Reading documentation carefully to select the right endpoint was more important than I expected - using the wrong one would mean collecting the wrong type\n",
    "of data entirely. This experience reinforced that data collection isn't just \"download and go\" -\n",
    "it requires understanding authentication, rate limits, error handling, and data documentation practices.\n",
    "#### What would you do differently if you had to collect data from a different city?\n",
    "Research the city's geography first - identify main urban center, suburbs, industrial zones, and green spaces\n",
    "Check where official government monitoring stations are located (equivalent to UK DEFRA) to align with official data for validation\n",
    "Consider collecting from MULTIPLE coordinates if API limits allow - e.g., city center, one suburb, one industrial area - to capture spatial variation\n",
    "Would still avoid extreme locations (airports, highways, parks) that aren't representative of typical urban exposure.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
